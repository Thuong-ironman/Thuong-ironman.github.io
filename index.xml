<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Welcome to my Blog!</title>
    <link>https://Thuong-ironman.github.io/</link>
    <description>Recent content on Welcome to my Blog!</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://Thuong-ironman.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Perception systems</title>
      <link>https://Thuong-ironman.github.io/post/sample3/</link>
      <pubDate>Sun, 27 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/post/sample3/</guid>
      <description>&lt;h1 id=&#34;camera&#34;&gt;Camera&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Camera Transformation&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Extrinsic camera matrix converts points from the world coordinates to camera coordinates, and depend on the position and orientation of the camera.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;World-to-camera: 3D-3D projection. Rotation and translation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Intrinsic camera matrix convert points from the camera coordinates to the pixel coordinates, and depend on the camera properties ( focal length, pixel dimensions, optical center, skew coefficient, lens distortion)&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Camera-to-image: 3D-2D projection. Loss of information (depth). Depends on the camera model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kalman and Bayesian Filters. How a car know its position?</title>
      <link>https://Thuong-ironman.github.io/blog/sample-2/</link>
      <pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/blog/sample-2/</guid>
      <description>&lt;p&gt;Sensors are noisy. The world is full of data and events that we want to measure and track, but we cannot rely on sensors to give us perfect information. The GPS in my car reports altitude. Each time I pass the same point on the road, it reports a slightly different altitude.&#xA;I work on computer vision, and I  need to track moving objects in images, and computer vision algorithms create very noisy and unreliable results.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kalman and Bayesian Filters. How a car know its position?</title>
      <link>https://Thuong-ironman.github.io/post/sample-2/</link>
      <pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/post/sample-2/</guid>
      <description>&lt;p&gt;Sensors are noisy. The world is full of data and events that we want to measure and track, but we cannot rely on sensors to give us perfect information. The GPS in my car reports altitude. Each time I pass the same point on the road, it reports a slightly different altitude.&#xA;I work on computer vision, and I  need to track moving objects in images, and computer vision algorithms create very noisy and unreliable results.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Design methods for unmanned vehicles</title>
      <link>https://Thuong-ironman.github.io/blog/sample1/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/blog/sample1/</guid>
      <description>&lt;h1 id=&#34;localisation-and-navigation&#34;&gt;Localisation and Navigation&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;State Estimation&#xA;What is a state estimator?&#xA;There are different definitions, according to the domian of application considered.&#xA;In a very broad sense, it can be defined as an algorithm that, given a sequence of measurements, reconstructs the internal state of a system. The measurements are collected from sensors.&#xA;Examples of sensors for UAVs:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPS;&lt;/li&gt;&#xA;&lt;li&gt;Magnetometer;&lt;/li&gt;&#xA;&lt;li&gt;Inertial Measurement Units;&lt;/li&gt;&#xA;&lt;li&gt;Gyroscopes;&lt;/li&gt;&#xA;&lt;li&gt;(Stereo) cameras;&lt;/li&gt;&#xA;&lt;li&gt;RGB-D cameras;&lt;/li&gt;&#xA;&lt;li&gt;Radio-Frequency Systems: Ultra-Wide Band (UWB), Radio Frequency IDentification (RFID);&lt;/li&gt;&#xA;&lt;li&gt;LiDAR&lt;/li&gt;&#xA;&lt;li&gt;And neuromophic sensors (Event cameras) - the one that I am doing research in recent year&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Static vs dynamic&#xA;The state estimates are different depending on the nature of the state and on the number and types of the available sensors.&#xA;Static estimators are used whenever the state can be determined with one single collections of measurements. In other words,&#xA;when the sensors give information on all the components of the state.&#xA;Dynamic estimators are used when the state can be reconstruced using the sensors and some other additional information constraints on the state.&#xA;Usually, dynamic estimators use sensor readings collected at different time instants and combine them with the state dynamic.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Design methods for unmanned vehicles</title>
      <link>https://Thuong-ironman.github.io/post/sample1/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/post/sample1/</guid>
      <description>&lt;h1 id=&#34;localisation-and-navigation&#34;&gt;Localisation and Navigation&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;State Estimation&#xA;What is a state estimator?&#xA;There are different definitions, according to the domian of application considered.&#xA;In a very broad sense, it can be defined as an algorithm that, given a sequence of measurements, reconstructs the internal state of a system. The measurements are collected from sensors.&#xA;Examples of sensors for UAVs:&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPS;&lt;/li&gt;&#xA;&lt;li&gt;Magnetometer;&lt;/li&gt;&#xA;&lt;li&gt;Inertial Measurement Units;&lt;/li&gt;&#xA;&lt;li&gt;Gyroscopes;&lt;/li&gt;&#xA;&lt;li&gt;(Stereo) cameras;&lt;/li&gt;&#xA;&lt;li&gt;RGB-D cameras;&lt;/li&gt;&#xA;&lt;li&gt;Radio-Frequency Systems: Ultra-Wide Band (UWB), Radio Frequency IDentification (RFID);&lt;/li&gt;&#xA;&lt;li&gt;LiDAR&lt;/li&gt;&#xA;&lt;li&gt;And neuromophic sensors (Event cameras) - the one that I am doing research in recent year&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Static vs dynamic&#xA;The state estimates are different depending on the nature of the state and on the number and types of the available sensors.&#xA;Static estimators are used whenever the state can be determined with one single collections of measurements. In other words,&#xA;when the sensors give information on all the components of the state.&#xA;Dynamic estimators are used when the state can be reconstruced using the sensors and some other additional information constraints on the state.&#xA;Usually, dynamic estimators use sensor readings collected at different time instants and combine them with the state dynamic.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://Thuong-ironman.github.io/archives/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/archives/</guid>
      <description></description>
    </item>
    <item>
      <title>About</title>
      <link>https://Thuong-ironman.github.io/about/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/about/</guid>
      <description>&lt;p&gt;Ciao! I&amp;rsquo;m Pham Cong Thuong (a.k.a. Elio), welcome to my blog! I&amp;rsquo;m a robotics software engineer and machine learning lover based in Genova, Italy.&lt;/p&gt;&#xA;&lt;p&gt;I mostly work on vision system on humanoid robot, especially on event-camera, rgb camera and lidar. My recent intellectual interest is in the three-pound thing making everything of the world - BRAIN (neuroscience). I have been fascinated by the BRAIN PBS shows and books of David Eagleman (Brain and Livewired). With the convergence of several technologies, powered by computational sciences, I think we are at the door of decoding the most mysterious thing in the world!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Portfolio</title>
      <link>https://Thuong-ironman.github.io/contact/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/contact/</guid>
      <description></description>
    </item>
    <item>
      <title></title>
      <link>https://Thuong-ironman.github.io/cv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://Thuong-ironman.github.io/cv/</guid>
      <description>&lt;h1 id=&#34;technical-skills&#34;&gt;Technical Skills&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Languages&lt;/strong&gt;: Python, C/C++, Matlab, Labview, Maple&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Hardware&lt;/strong&gt;: Raspberry Pi, Jetson Nano, Arduino&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Developer Tools&lt;/strong&gt;: Git, Docker, Google Cloud Platform, VS Code, Visual Studio, Jupyter Notebook&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Libraries&lt;/strong&gt;: Pandas, NumPy, Matplotlib&lt;/p&gt;&#xA;&lt;h1 id=&#34;education&#34;&gt;Education&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Sep 2021 - Mar 2024: University of Trento, Trento, Italy&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Master in Electronics and Robotics&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Sep 2013 - Sep 2018: Hanoi University of Science and Technology, Hanoi, Vietnam&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Degree of Engineer in Mechatronics Engineering&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;experience&#34;&gt;Experience&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;July 2024 - Now:  Robotics Research Fellow&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
