<!doctype html>













































<html
  class="not-ready lg:text-base"
  style="--bg: #faf8f1"
  lang="en-us"
  dir="ltr"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>A beautiful algorithm in Reiforcement learning - TD learning - Thuong Pham Blog</title>

  
  <meta name="theme-color" />

  
  
  
  
  <meta name="description" content="TD learning" />
  <meta name="author" content="thuong.pham" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://Thuong-ironman.github.io/main.min.css" />

  
  
  
  
  
  <link rel="preload" as="image" href="https://Thuong-ironman.github.io/theme.png" />

  
  
  
  
  <link rel="preload" as="image" href="https://www.gravatar.com/avatar/84d919d231f1963555eec79fa3ef9384?s=160&amp;d=identicon" />
  
  

  
  
  <link rel="preload" as="image" href="https://Thuong-ironman.github.io/github.svg" />
  
  <link rel="preload" as="image" href="https://Thuong-ironman.github.io/linkedin.svg" />
  
  

  
  
  <script
    defer
    src="https://Thuong-ironman.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  
  
  
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
  crossorigin="anonymous"
></script>


<script>
  document.addEventListener('DOMContentLoaded', () =>
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
      ],
      
      throwOnError: false,
    }),
  );
</script>

  
  
  

  
  <link
    rel="icon"
    href="https://Thuong-ironman.github.io/favicon.ico"
  />
  <link
    rel="apple-touch-icon"
    href="https://Thuong-ironman.github.io/apple-touch-icon.png"
  />

  
  <meta name="generator" content="Hugo 0.140.2">

  
  
  
  
  
  
  <meta itemprop="name" content="A beautiful algorithm in Reiforcement learning - TD learning">
  <meta itemprop="description" content="A brief guide to setup KaTeX">
  <meta itemprop="datePublished" content="2025-01-03T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-01-03T00:00:00+00:00">
  <meta itemprop="wordCount" content="387">
  
  <meta property="og:url" content="https://Thuong-ironman.github.io/post/math-typesetting/">
  <meta property="og:site_name" content="Thuong Pham Blog">
  <meta property="og:title" content="A beautiful algorithm in Reiforcement learning - TD learning">
  <meta property="og:description" content="A brief guide to setup KaTeX">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2025-01-03T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-03T00:00:00+00:00">

  
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="A beautiful algorithm in Reiforcement learning - TD learning">
  <meta name="twitter:description" content="A brief guide to setup KaTeX">

  
  

  
  <link rel="canonical" href="https://Thuong-ironman.github.io/post/math-typesetting/" />
  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[4.5rem] max-w-[--w] px-8 lg:justify-center">
  <div class="relative z-50 ltr:mr-auto rtl:ml-auto flex items-center">
    <a class="-translate-y-[1px] text-2xl font-medium" href="https://Thuong-ironman.github.io/"
      >Thuong Pham Blog</a
    >
    <div
      class="btn-dark text-[0] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 ltr:-mr-8 rtl:-ml-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse">
      
      <a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      >
      
      <a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/contact/"
        >Contact</a
      >
      
    </nav>
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 rtl:space-x-reverse dark:invert ltr:lg:ml-14 rtl:lg:mr-14 lg:mt-0 lg:items-center"
    >
      
      <a
        class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href="https://github.com/Thuong-ironman"
        target="_blank"
        rel="me"
      >
        github
      </a>
      
      <a
        class="h-7 w-7 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./linkedin.svg)"
        href="https://linkedin.com/in/thuongpham31195"
        target="_blank"
        rel="me"
      >
        linkedin
      </a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100vh-9rem)] max-w-[--w] px-8 pb-16 pt-14 dark:prose-invert"
    >
      

<article>
  <header class="mb-14">
    <h1 class="!my-0 pb-2.5">A beautiful algorithm in Reiforcement learning - TD learning</h1>

    
    <div class="text-xs antialiased opacity-60">
      
      <time>Jan 3, 2025</time>
      
      
      
      
      <span class="mx-1">&middot;</span>
      <span>thuong.pham</span>
      
    </div>
    
  </header>

  <section><p>TD learning</p>
<h1 id="introduction-to-temporal-difference-td-learning">Introduction to Temporal Difference (TD) Learning</h1>
<p>Temporal Difference (TD) learning is a foundational concept in reinforcement learning (RL), a branch of machine learning where agents learn to make decisions by interacting with an environment. TD learning combines ideas from <strong>Monte Carlo methods</strong> and <strong>Dynamic Programming</strong>, making it a powerful approach for learning value functions directly from experience.</p>
<h2 id="key-concepts">Key Concepts</h2>
<h3 id="1-reinforcement-learning-framework">1. Reinforcement Learning Framework</h3>
<p>An RL problem is defined by an agent interacting with an environment over discrete time steps. At each time step ( t ):</p>
<ul>
<li>The agent observes a state ( s_t ),</li>
<li>Takes an action ( a_t ),</li>
<li>Receives a reward ( r_{t+1} ),</li>
<li>And transitions to a new state ( s_{t+1} ).</li>
</ul>
<h3 id="2-value-function">2. Value Function</h3>
<p>The value function ( V(s) ) estimates the expected future reward starting from state ( s ).<br>
The agent&rsquo;s goal is to learn a value function that helps it choose actions maximizing long-term rewards.</p>
<h3 id="3-temporal-difference-learning">3. Temporal Difference Learning</h3>
<p>Unlike Monte Carlo methods, which wait until the end of an episode to update values, TD learning updates the value estimates incrementally at each step.<br>
The key idea is to use the difference between successive value estimates—called the <strong>TD error</strong>—to adjust ( V(s) ).</p>
<h2 id="td-learning-formula">TD Learning Formula</h2>
<p>For a given state ( s_t ), the TD update is:</p>
<p>[
V(s_t) \leftarrow V(s_t) + \alpha \left[ r_{t+1} + \gamma V(s_{t+1}) - V(s_t) \right]
]</p>
<p>Where:</p>
<ul>
<li>( \alpha ) is the learning rate.</li>
<li>( \gamma ) is the discount factor (controls the importance of future rewards).</li>
<li>( r_{t+1} + \gamma V(s_{t+1}) - V(s_t) ) is the <strong>TD error</strong>.</li>
</ul>
<h2 id="advantages-of-td-learning">Advantages of TD Learning</h2>
<ul>
<li><strong>Efficiency</strong>: Updates occur after every time step, making TD learning faster than Monte Carlo methods.</li>
<li><strong>Model-Free</strong>: TD learning does not require a model of the environment.</li>
<li><strong>Online Learning</strong>: Suitable for continuous tasks where episodes do not have a defined end.</li>
</ul>
<h2 id="types-of-td-methods">Types of TD Methods</h2>
<ol>
<li><strong>TD(0)</strong>: The simplest form of TD learning where updates are based on the immediate next state.</li>
<li><strong>TD(λ)</strong>: A generalization that combines TD(0) and Monte Carlo methods, incorporating eligibility traces to balance short-term and long-term rewards.</li>
</ol>
<h2 id="applications-of-td-learning">Applications of TD Learning</h2>
<ul>
<li>Game-playing AI (e.g., TD-Gammon for backgammon).</li>
<li>Robot control.</li>
<li>Financial modeling.</li>
<li>Human decision-making simulations.</li>
</ul>
<p>TD learning is central to many advanced RL algorithms, including <strong>Q-Learning</strong> and <strong>SARSA</strong>, making it a crucial stepping stone for building intelligent agents.</p></section>

  
  

  
  
  
  
  <nav
    class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg !leading-[1.2] *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"
  >
    
    
    <a class="ltr:ml-auto rtl:mr-auto justify-end pl-3" href="https://Thuong-ironman.github.io/post/markdown-syntax/"
      ><span>Markdown Syntax Guide</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a
    >
    
  </nav>
  
  

  
  

  
  

  


  
</article>


    </main>

    <footer
  class="mx-auto flex h-[4.5rem] max-w-[--w] items-center px-8 text-xs uppercase tracking-wider opacity-60"
>
  <div class="mr-auto">
  
    &copy; 2025
    <a class="link" href="https://Thuong-ironman.github.io/">Thuong Pham Blog</a>
  
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >powered by hugo️️</a
  >️
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >hugo-paper</a
  >
</footer>

  </body>
</html>
